{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08505313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changes made on branch main\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from normal import do_normal\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "def load_model():\n",
    "    \n",
    "    saved_model = DeepNN(input_dim)\n",
    "    saved_model.load_state_dict(torch.load(\"lung_cancer_model.pth\"))\n",
    "    saved_model.eval()\n",
    "\n",
    "    saved_model_wb = saved_model.model\n",
    "    return saved_model_wb\n",
    "\n",
    "# for idx, layer in enumerate(saved_model.model):\n",
    "#     if isinstance(layer, nn.Linear):\n",
    "#         print(f\"Layer {idx} - Linear\")\n",
    "#         print(f\"  Weights shape: {layer.weight.shape}\")\n",
    "#         print(f\"  Weights:\\n{layer.weight.data}\\n\")\n",
    "#         print(f\"  Biases shape: {layer.bias.shape}\")\n",
    "#         print(f\"  Biases:\\n{layer.bias.data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "# input_values = [ 0.9526,  1.2598, -1.1353, -1.1504, -0.9968, -1.0032,  0.9903, -1.4351,\n",
    "#          0.8925, -1.1205,  0.8925,  0.8522,  0.7487,  1.0635,  0.8925]\n",
    "# input_tensor = torch.tensor(input_values)\n",
    "\n",
    "# print(input_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad268042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d87a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0644, 0.9512, 1.0228, 1.0692, 0.9853, 0.9568, 0.9209, 0.9285, 0.9774,\n",
      "        1.0885, 1.0384, 1.0883, 0.9562, 0.9786, 1.0115])\n"
     ]
    }
   ],
   "source": [
    "# enc_vec = torch.tensor(np.random.uniform(0.9, 1.1, len(input_values)), dtype=torch.float32)\n",
    "# print(enc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2df9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6032)\n"
     ]
    }
   ],
   "source": [
    "# an_plus_1 = torch.tensor(np.random.uniform(1, 2), dtype=torch.float32)\n",
    "# print(an_plus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45f237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0140,  1.1983, -1.1612, -1.2300, -0.9822, -0.9598,  0.9120, -1.3324,\n",
      "         0.8723, -1.2196,  0.9267,  0.9274,  0.7159,  1.0408,  0.9028])\n"
     ]
    }
   ],
   "source": [
    "# enc_inp = enc_vec * input_tensor\n",
    "# print(enc_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfc7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decryption vector\n",
    "# dec_vec = 1 / enc_vec\n",
    "# dec_vec = torch.cat((dec_vec, torch.tensor([1 / an_plus_1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 1 #temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2109467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_vec = dec_vec/k\n",
    "# eval_vec = eval_vec.view(len(input_values)+1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be209649",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43menc_vec\u001b[49m)\n\u001b[0;32m      2\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'enc_vec' is not defined"
     ]
    }
   ],
   "source": [
    "# input_dim = len(enc_vec)\n",
    "# output_dim = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28efc8a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_model_wb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msaved_model_wb\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saved_model_wb' is not defined"
     ]
    }
   ],
   "source": [
    "print(saved_model_wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769554d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64, 15])\n"
     ]
    }
   ],
   "source": [
    "print(saved_model_wb[0].bias.data.shape)\n",
    "print(saved_model_wb[0].weight.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488e230",
   "metadata": {},
   "source": [
    "LAYER 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a15d6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a250b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "input_layer_weights = saved_model_wb[0].weight.data.T\n",
    "print(input_layer_weights.shape)\n",
    "input_layer_bias = saved_model_wb[0].bias.data\n",
    "print(input_layer_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28ed5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_layer_calc(activation_matrix,saved_model_wb,enc_inp,eval_vec):\n",
    "  input_layer_weights = saved_model_wb[0].weight.data.T\n",
    "  input_layer_bias = saved_model_wb[0].bias.data\n",
    "  for col_idx in range(input_layer_weights.shape[1]):\n",
    "    # Element-wise multiplication with the column vector of input_layer_weights\n",
    "    col_vector = input_layer_weights[:, col_idx]\n",
    "    elementwise_product = enc_inp * col_vector\n",
    "    \n",
    "    # Add (an+1 * bias for that column)\n",
    "    elementwise_product = torch.cat((elementwise_product, (an_plus_1 * input_layer_bias[col_idx]).unsqueeze(0)))\n",
    "    \n",
    "    # Store as a row vector in activation matrix\n",
    "    activation_matrix.append(elementwise_product)\n",
    "\n",
    "# Convert activation_matrix to a tensor\n",
    "    activation_matrix = torch.stack(activation_matrix)\n",
    "    print(activation_matrix)\n",
    "    print(activation_matrix.shape)\n",
    "    relu_output = []\n",
    "\n",
    "    for row_vector in activation_matrix:\n",
    "        # Compute the sum of elements in the row vector\n",
    "        row_sum = torch.matmul(row_vector,eval_vec)\n",
    "        # row_sum = row_vector.sum()\n",
    "        # Apply ReLU activation\n",
    "        relu_value = F.relu(row_sum)\n",
    "        if relu_value == 0:\n",
    "            row_vector.zero_()\n",
    "        # Append the result to relu_output\n",
    "        relu_output.append(relu_value)\n",
    "\n",
    "    relu_output = torch.tensor(relu_output)\n",
    "    activation_matrix = torch.stack([row_vector if relu_value > 0 else torch.zeros_like(row_vector) \n",
    "                                                for row_vector, relu_value in zip(activation_matrix, relu_output)])\n",
    "    return activation_matrix\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a422ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for col_idx in range(input_layer_weights.shape[1]):\n",
    "#     # Element-wise multiplication with the column vector of input_layer_weights\n",
    "#     col_vector = input_layer_weights[:, col_idx]\n",
    "#     elementwise_product = enc_inp * col_vector\n",
    "    \n",
    "#     # Add (an+1 * bias for that column)\n",
    "#     elementwise_product = torch.cat((elementwise_product, (an_plus_1 * input_layer_bias[col_idx]).unsqueeze(0)))\n",
    "    \n",
    "#     # Store as a row vector in activation matrix\n",
    "#     activation_matrix.append(elementwise_product)\n",
    "\n",
    "# # Convert activation_matrix to a tensor\n",
    "# activation_matrix = torch.stack(activation_matrix)\n",
    "# print(activation_matrix)\n",
    "# print(activation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5e7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a9caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu_output = []\n",
    "\n",
    "# for row_vector in activation_matrix:\n",
    "#     # Compute the sum of elements in the row vector\n",
    "#     row_sum = torch.matmul(row_vector,eval_vec)\n",
    "#     # row_sum = row_vector.sum()\n",
    "#     # Apply ReLU activation\n",
    "#     relu_value = F.relu(row_sum)\n",
    "#     if relu_value == 0:\n",
    "#         row_vector.zero_()\n",
    "#     # Append the result to relu_output\n",
    "#     relu_output.append(relu_value)\n",
    "\n",
    "# relu_output = torch.tensor(relu_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ab3a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_matrix = torch.stack([row_vector if relu_value > 0 else torch.zeros_like(row_vector) \n",
    "#                                         for row_vector, relu_value in zip(activation_matrix, relu_output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6ef0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_layer_calc(activation_matrix,saved_model_wb,eval_vec):\n",
    "  for i in range(2,12,2):\n",
    "    intermediate_weights = saved_model_wb[i].weight.data.T\n",
    "    intermediate_biases= saved_model_wb[i].bias.data\n",
    "    \n",
    "    activation_matrix_new = []\n",
    "\n",
    "    for col_idx in range(intermediate_weights.shape[1]):\n",
    "    # Get the column vector of intermediate_weights\n",
    "      col_vector = intermediate_weights[:, col_idx]\n",
    "    \n",
    "    # Scale each row of activation_matrix using the corresponding weight\n",
    "      scaled_activation = activation_matrix * col_vector.view(-1,1)\n",
    "    \n",
    "    # Sum the scaled activation matrix column-wise to generate a row vector\n",
    "      row_vector = scaled_activation.sum(dim=0)\n",
    "    \n",
    "    # Add (an+1 * bias for the current column) to the last element of the row vector\n",
    "      row_vector[-1] += an_plus_1 * intermediate_biases[col_idx]\n",
    "    \n",
    "    # Append the row vector to activation_matrix_new\n",
    "      activation_matrix_new.append(row_vector)\n",
    "\n",
    "    activation_matrix_new = torch.stack(activation_matrix_new)\n",
    "\n",
    "    relu_output = []\n",
    "\n",
    "    for row_vector in activation_matrix_new:\n",
    "    # Compute the sum of elements in the row vector\n",
    "      row_sum = torch.matmul(row_vector,eval_vec)\n",
    "    # Apply ReLU activation\n",
    "      relu_value = F.relu(row_sum)\n",
    "      if relu_value == 0:\n",
    "        row_vector.zero_()\n",
    "    # Append the result to relu_output\n",
    "      relu_output.append(relu_value)\n",
    "\n",
    "    relu_output = torch.tensor(relu_output)\n",
    "    activation_matrix = torch.stack([row_vector if relu_value > 0 else torch.zeros_like(row_vector) \n",
    "                                        for row_vector, relu_value in zip(activation_matrix_new, relu_output)])\n",
    "    print(activation_matrix.shape)\n",
    "    \n",
    "  return activation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baae77ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0733, -0.0914, -0.2212, -0.2995, -0.1976,  0.0763, -0.2186,  0.2842,\n",
      "         -0.0270, -0.1663,  0.1792,  0.1800,  0.0154, -0.1407, -0.1496,  0.1440]])\n",
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "activation_matrix = input_layer_calc(activation_matrix,input_layer_weights,input_layer_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d930f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_matrix = intermediate_layer_calc(activation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8036a4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "print(activation_matrix.shape)\n",
    "\n",
    "dec_vec = dec_vec.view(16,1)\n",
    "print(dec_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66734b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "decrypted_output = torch.matmul(activation_matrix,dec_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45ee73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2952]])\n"
     ]
    }
   ],
   "source": [
    "print(decrypted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee8aebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5733)\n"
     ]
    }
   ],
   "source": [
    "final_ans = torch.sigmoid(decrypted_output[0][0])\n",
    "\n",
    "print(final_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdef322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.049781</td>\n",
       "      <td>-0.204116</td>\n",
       "      <td>-1.135292</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>1.003241</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>-1.009756</td>\n",
       "      <td>-1.435063</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>-1.120480</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>-1.335584</td>\n",
       "      <td>1.063501</td>\n",
       "      <td>-1.120480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.952579</td>\n",
       "      <td>-1.180082</td>\n",
       "      <td>0.880830</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>1.003241</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.990338</td>\n",
       "      <td>-1.435063</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>-1.120480</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>-1.173424</td>\n",
       "      <td>-1.335584</td>\n",
       "      <td>1.063501</td>\n",
       "      <td>0.892475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.259833</td>\n",
       "      <td>-1.135292</td>\n",
       "      <td>-1.150351</td>\n",
       "      <td>-0.996769</td>\n",
       "      <td>-1.003241</td>\n",
       "      <td>0.990338</td>\n",
       "      <td>-1.435063</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>-1.120480</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>0.748736</td>\n",
       "      <td>1.063501</td>\n",
       "      <td>0.892475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.952579</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>-1.135292</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>-0.996769</td>\n",
       "      <td>0.996769</td>\n",
       "      <td>0.990338</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>-1.335584</td>\n",
       "      <td>1.063501</td>\n",
       "      <td>0.892475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952579</td>\n",
       "      <td>0.283867</td>\n",
       "      <td>-1.135292</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>1.003241</td>\n",
       "      <td>-1.003241</td>\n",
       "      <td>-1.009756</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>-1.120480</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.892475</td>\n",
       "      <td>0.852207</td>\n",
       "      <td>0.748736</td>\n",
       "      <td>1.063501</td>\n",
       "      <td>0.892475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.049781 -0.204116 -1.135292  0.869300  1.003241  0.996769 -1.009756   \n",
       "1  0.952579 -1.180082  0.880830  0.869300  1.003241  0.996769  0.990338   \n",
       "2  0.952579  1.259833 -1.135292 -1.150351 -0.996769 -1.003241  0.990338   \n",
       "3  0.952579  0.893846 -1.135292  0.869300 -0.996769  0.996769  0.990338   \n",
       "4  0.952579  0.283867 -1.135292  0.869300  1.003241 -1.003241 -1.009756   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -1.435063  0.892475  0.892475 -1.120480  0.852207 -1.335584  1.063501   \n",
       "1 -1.435063  0.892475 -1.120480  0.892475 -1.173424 -1.335584  1.063501   \n",
       "2 -1.435063  0.892475 -1.120480  0.892475  0.852207  0.748736  1.063501   \n",
       "3  0.696833  0.892475  0.892475  0.892475  0.852207 -1.335584  1.063501   \n",
       "4  0.696833 -1.120480  0.892475  0.892475  0.852207  0.748736  1.063501   \n",
       "\n",
       "         14  \n",
       "0 -1.120480  \n",
       "1  0.892475  \n",
       "2  0.892475  \n",
       "3  0.892475  \n",
       "4  0.892475  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data= pd.read_csv(\"test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6aec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  1.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "y_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92c36f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad24759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc_vec = torch.tensor(np.random.uniform(0.9, 1.1, 15), dtype=torch.float32)\n",
    "an_plus_1 = torch.tensor(np.random.uniform(1, 2), dtype=torch.float32)\n",
    "# Decryption vector\n",
    "dec_vec = 1 / enc_vec\n",
    "dec_vec = torch.cat((dec_vec, torch.tensor([1 / an_plus_1])))\n",
    "k = 1 #temporary\n",
    "eval_vec = dec_vec/k\n",
    "eval_vec = eval_vec.view(16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d7a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_data(input_values):\n",
    "  input_tensor = torch.tensor(input_values)\n",
    "  enc_inp = enc_inp = enc_vec * input_tensor\n",
    "  return enc_inp\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4dc8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_wb = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9677ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_ans(activation_matrix,dec_vec):\n",
    "  dec_vec = dec_vec.view(16,1)\n",
    "  decrypted_output = torch.matmul(activation_matrix,dec_vec)\n",
    "  final_ans = torch.sigmoid(decrypted_output[0][0])\n",
    "  return final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a8050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsavnn_model_pred(input_values,eval_vec):\n",
    "  enc_inp = encrypt_data(input_values)\n",
    "  activation_matrix =[]\n",
    "  activation_matrix = input_layer_calc(activation_matrix,saved_model_wb,enc_inp,eval_vec)\n",
    "  activation_matrix = intermediate_layer_calc(activation_matrix,saved_model_wb,eval_vec)\n",
    "  return activation_matrix\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e653c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\susha\\AppData\\Local\\Temp\\ipykernel_17400\\4274733193.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  input_tensor = torch.tensor(input_values)\n",
      "C:\\Users\\susha\\AppData\\Local\\Temp\\ipykernel_17400\\4274733193.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(input_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0049,  0.0008, -0.0541,  0.0033, -0.0024, -0.0420, -0.0362,  0.0055,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056, -0.0019, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0046,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0049, -0.0541, -0.0043,  0.0023,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0035, -0.0541,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0011, -0.0541,  0.0033, -0.0024,  0.0423, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134,  0.0043,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0025, -0.0541, -0.0043, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077, -0.0019, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0050,  0.0420, -0.0043,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0044,  0.0420, -0.0043,  0.0023,  0.0423, -0.0362, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0006,  0.0420,  0.0033, -0.0024,  0.0423, -0.0362, -0.0027,\n",
      "          0.0060, -0.0168, -0.0054, -0.0077,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0003,  0.0420,  0.0033,  0.0023,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168, -0.0054,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0022,  0.0420, -0.0043,  0.0023,  0.0423, -0.0362,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0025,  0.0420, -0.0043,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0041,  0.0420,  0.0033, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "         -0.0076,  0.0134,  0.0043, -0.0077,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0022,  0.0420, -0.0043,  0.0023,  0.0423, -0.0362,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0022,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "         -0.0076, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0008,  0.0420, -0.0043,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "          0.0060, -0.0168, -0.0054, -0.0077,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0058, -0.0541,  0.0033,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0058,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "         -0.0076, -0.0168, -0.0054, -0.0077, -0.0019,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0058, -0.0541,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0088, -0.0541,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054, -0.0077,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0013,  0.0420, -0.0043,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "         -0.0076, -0.0168, -0.0054, -0.0077,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0044,  0.0420,  0.0033, -0.0024, -0.0420, -0.0362, -0.0027,\n",
      "         -0.0076, -0.0168, -0.0054,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0020, -0.0541, -0.0043,  0.0023, -0.0420, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0039,  0.0420,  0.0033, -0.0024,  0.0423, -0.0362,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0063, -0.0541,  0.0033, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0030, -0.0541, -0.0043, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077, -0.0019, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0013,  0.0420,  0.0033, -0.0024,  0.0423, -0.0362,  0.0055,\n",
      "         -0.0076, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0020,  0.0420,  0.0033, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "         -0.0076, -0.0168, -0.0054, -0.0077,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0031,  0.0420, -0.0043,  0.0023,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0006,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0065, -0.0541, -0.0043,  0.0023, -0.0420,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0002,  0.0420,  0.0033, -0.0024,  0.0423, -0.0362,  0.0055,\n",
      "         -0.0076, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0003,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0022, -0.0541, -0.0043,  0.0023, -0.0420, -0.0362, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077, -0.0019, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0017, -0.0541,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0087, -0.0541,  0.0033, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0044,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "         -0.0076,  0.0134,  0.0043,  0.0056,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0027,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "         -0.0076, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0017, -0.0541,  0.0033, -0.0024,  0.0423, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0031, -0.0541,  0.0033, -0.0024, -0.0420, -0.0362,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0068, -0.0541,  0.0033, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "         -0.0076,  0.0134,  0.0043, -0.0077, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0044,  0.0420,  0.0033, -0.0024, -0.0420,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0044,  0.0420,  0.0033, -0.0024, -0.0420, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0068,  0.0420,  0.0033, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060,  0.0134, -0.0054, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0074,  0.0420,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0006, -0.0541,  0.0033, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0035, -0.0541,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0055,  0.0420,  0.0033, -0.0024, -0.0420, -0.0362, -0.0027,\n",
      "          0.0060, -0.0168, -0.0054, -0.0077,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0002, -0.0541, -0.0043,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "         -0.0076, -0.0168, -0.0054, -0.0077,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0031,  0.0420, -0.0043,  0.0023,  0.0423, -0.0362, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0044, -0.0541,  0.0033,  0.0023,  0.0423, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134,  0.0043,  0.0056,  0.0011,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0058, -0.0541,  0.0033, -0.0024, -0.0420, -0.0362,  0.0055,\n",
      "          0.0060,  0.0134, -0.0054,  0.0056, -0.0019, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0011,  0.0420,  0.0033, -0.0024, -0.0420, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0031, -0.0541, -0.0043,  0.0023,  0.0423,  0.0355, -0.0027,\n",
      "          0.0060, -0.0168,  0.0043,  0.0056,  0.0011,  0.0123,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0053,  0.0420,  0.0033, -0.0024, -0.0420, -0.0362, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054,  0.0056,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0072, -0.0541,  0.0033,  0.0023, -0.0420,  0.0355, -0.0027,\n",
      "         -0.0076,  0.0134, -0.0054, -0.0077,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0006, -0.0541,  0.0033, -0.0024, -0.0420, -0.0362,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043, -0.0077, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049, -0.0049,  0.0420,  0.0033, -0.0024,  0.0423,  0.0355,  0.0055,\n",
      "          0.0060, -0.0168,  0.0043, -0.0077, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045, -0.0030, -0.0541,  0.0033, -0.0024,  0.0423, -0.0362,  0.0055,\n",
      "         -0.0076,  0.0134,  0.0043,  0.0056,  0.0011, -0.0140, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[-0.0045,  0.0041,  0.0420, -0.0043,  0.0023,  0.0423, -0.0362,  0.0055,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019,  0.0123, -0.0104, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0003,  0.0420, -0.0043,  0.0023, -0.0420, -0.0362, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043,  0.0056, -0.0019, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "tensor([[ 0.0049,  0.0031, -0.0541, -0.0043, -0.0024, -0.0420,  0.0355, -0.0027,\n",
      "          0.0060,  0.0134,  0.0043, -0.0077,  0.0011, -0.0140,  0.0083, -0.0020]])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([48, 16])\n",
      "torch.Size([32, 16])\n",
      "torch.Size([16, 16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([1, 16])\n",
      "\n",
      " Test Accuracy: 96.77 %\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.97      1.00      0.98        60\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.48      0.50      0.49        62\n",
      "weighted avg       0.94      0.97      0.95        62\n",
      "\n",
      "CPU times: total: 672 ms\n",
      "Wall time: 705 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "for index, row in test_data.iterrows():\n",
    "  row_input = encrypt_data(row) \n",
    "  row_input = encrypt_data(row).float()\n",
    "  eval_vec = eval_vec.float()\n",
    "\n",
    "  final_activation_matrix = bsavnn_model_pred(row_input,eval_vec)\n",
    "  final_ans = decrypt_ans(final_activation_matrix,dec_vec)\n",
    "  predicted_classes = (final_ans > 0.5).float()\n",
    "  y_pred.append(predicted_classes.item())\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"\\n Test Accuracy:\", round(acc * 100, 2), \"%\")\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2bdf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Accuracy: 96.77 %\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         2\n",
      "         1.0       0.97      1.00      0.98        60\n",
      "\n",
      "    accuracy                           0.97        62\n",
      "   macro avg       0.48      0.50      0.49        62\n",
      "weighted avg       0.94      0.97      0.95        62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\susha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba22a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
